{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape BMO mutual funds [the site](https://www.bmo.com/home/personal/banking/investments/mutual-funds/navigator/funds/mutual-funds-list/funds-overview\")\n",
    "\n",
    "The website lists all BMO mutuals in the market. Since it is in a tabular format (`tr` and `td` tags), it's easy to parse the HTML and extract the data. Here is a quick summary of the process:\n",
    "\n",
    "1. Create a Chrome driver using `Selenium`, and go to the specified URL.\n",
    "2. Parse the HTML, and find all `tr` tags with the `valign` attribute set to `center`.\n",
    "3. Extract data from each `tr` into a list. \n",
    "4. Convert the list into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData():\n",
    "    \"\"\"Extracts the data from the BMO website.\n",
    "    \n",
    "    Returns:\n",
    "        A list of dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    # create a list to store cleaned data\n",
    "    results = list()\n",
    "    \n",
    "    # wait until the tr appear\n",
    "    trs = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, '//tr[@valign=\"center\"]'))\n",
    "    )\n",
    "    \n",
    "    for tr in trs:\n",
    "    \n",
    "        # the BMO fund ID\n",
    "        fundID = tr.get_attribute('id')\n",
    "        fundID = fundID.rsplit(\"_\")[-1]\n",
    "\n",
    "        # locate the <a> and extract href\n",
    "        profileURL = tr.find_element_by_tag_name('a').get_attribute('href')    \n",
    "\n",
    "        # the attribtues are stored in the listCellWithBorders class\n",
    "        # find them all, and extract text\n",
    "\n",
    "        attrs = tr.find_elements_by_class_name('listCellWithBorders')\n",
    "        fundName, _, price, assetClass, assets, dateCreated = list(map(lambda x: x.text, attrs))\n",
    "\n",
    "        # insert the data into the list\n",
    "        results.append({\n",
    "            'Fund ID': fundID,\n",
    "            'Fund Name': fundName,\n",
    "            'Price': price,\n",
    "            'Asset Class': assetClass,\n",
    "            'Date Started': dateCreated,\n",
    "            'Fund Profile': profileURL\n",
    "        })\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bmo.com/home/personal/banking/investments/mutual-funds/navigator/funds/mutual-funds-list/funds-overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('./chromedriver')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bmo = extractData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape BMO portfolios \n",
    "\n",
    "The portfolio data is under the drop-down at the top right. The code below does the following actions:\n",
    "\n",
    "1. Locate the drop-down.\n",
    "2. Go to each option in the drop-down, and extract the data.\n",
    "3. Append the data to the original list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip the first two options\n",
    "page_index = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while page_index < 10:\n",
    "    \n",
    "    # locate the drop-down     \n",
    "    select = Select(driver.find_element_by_id('portfolio'))\n",
    "    select.select_by_index(page_index)\n",
    "    \n",
    "    # increment the page counter     \n",
    "    page_index += 1\n",
    "    \n",
    "    # append new data to the original list\n",
    "    bmo += extractData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver the data into a pandas dataframe\n",
    "bmo = pd.DataFrame(bmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Historical Price\n",
    "\n",
    "Now, we already have a Data Frame that contains the basic information about all BMO Mutual Funds. However, the price column represents the latest price. It would be great if we can collect all historical data. After inspecting the following URL: `https://bmomf.lipperweb.com/Profile/HistoryView?symbol=45121:17695&tab=History&timeFrame=Year&interval=0&period=1&startDate=&endDate=&isTimePeriodChange=true&lang=en`, I figure out the pattern to retrieve the recorded information. The URL consists of the following components:\n",
    "\n",
    "1. The base URL: `https://bmomf.lipperweb.com/Profile/HistoryView`\n",
    "2. The query strings:\n",
    "    \n",
    "    * symbol: 45121:17695\n",
    "    * etc.\n",
    "\n",
    "Noted that 17695 is the Fund ID, and the code 45121 never changes. If we request this URL by iterating all our fund IDs, we can get all historical prices. Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters and headers for the HTTP get request\n",
    "\n",
    "params = {\n",
    "    \"symbol\": \"\",\n",
    "    \"tab\": \"History\",\n",
    "    \"timeFrame\": \"Year\",\n",
    "    \"interval\": \"0\",\n",
    "    \"period\": \"1\",\n",
    "    \"startDate\": \"\",\n",
    "    \"endDate\": \"\",\n",
    "    \"isTimePeriodChange\": True,\n",
    "    \"lang\": \"en\",\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"text/html, */*; q=0.01\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Cookie\": \"_ga=GA1.2.1526468817.1615351851; _gid=GA1.2.881144454.1615351851; _gat=1\",\n",
    "    \"Host\": \"bmomf.lipperweb.com\",\n",
    "    \"Referer\": \"https://bmomf.lipperweb.com/bmomf/profile/?symbol=45121:94792&lang=en\",\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseURL = 'https://bmomf.lipperweb.com/Profile/HistoryView'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, fund in bmo.iterrows():\n",
    "    \n",
    "    print(fund['Fund Name'])\n",
    "    \n",
    "    # use fstring to replace the value\n",
    "    params['symbol'] = f\"45121:{fund['Fund ID']}\"\n",
    "\n",
    "    # send the request\n",
    "    res = requests.get(baseURL, params=params, headers=headers)\n",
    "    \n",
    "    time.sleep(random.uniform(0.0, 2.0))\n",
    "    \n",
    "    # the response is in HTML format, I use BeautifulSoup to parse it\n",
    "    document = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "    # the data is stored in the <td></td>. find them all\n",
    "    tds = document.find_all('td', {'style': 'text-align: center;'})\n",
    "    \n",
    "    # extract the inner text for all tds\n",
    "    values = [ td.text.strip() for td in tds ]\n",
    "    \n",
    "    # We have a 1d array, but each data point consists of 6 columns. \n",
    "    # The following code turns every six elements into a list. In \n",
    "    # other words, we are converting the 1d array to a 2d array\n",
    "    # Here is an quick example. Before:\n",
    "    # ['8/25/2021', 13.8073, ..., '8/24/2021', 13.8541, ...]\n",
    "    # After: [['8/25/2021', 13.8073, ...], ['8/24/2021', 13.8541, ...]]\n",
    "    \n",
    "    values = [ [fund['Fund ID']] + values[i:i+6] for i in range(0, len(values), 6)]\n",
    "    \n",
    "    # append the values to the retuslt list\n",
    "    results += values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column name\n",
    "cols = [\n",
    "    'Fund ID',\n",
    "    'Effective Date',\n",
    "    'NAV',\n",
    "    'Income',\n",
    "    'Capital Gain',\n",
    "    'Total Distribution',\n",
    "    'Reinvestment Price'\n",
    "]\n",
    "\n",
    "# convert the data into a df\n",
    "prices = pd.DataFrame(values, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
